# Daily Insights 2026-02-26

## Source
- 2026-02-26 15:49:19 UTC | screenshot | ### 核心内容

- **测试对象**：Qwen3.5 的 35B 和 27B 模型，均使用 FP8 精度。
- **硬件配置**：单卡 4090，显存 48G。
- **测试结果**：
  - **35B 模型**：
    - 单卡请求速度 120-130 时，200k 上下文仅能衰退到 90，性能不足。
  - **27B 模型**：
    - Dense 模型性能较好，输出稳定在 20t/s。
    - 200k 前缓冲 4k 输入时，保持 19t/s 左右，prefill 时间约 200 毫秒。
    - 使用 Agent Teams 并发，六个并发稳定输出 120t，任务完
- 2026-02-26 16:27:35 UTC | screenshot | ### 核心内容
- **研究背景**：探讨了LLM（大语言模型）的Base与Instruct之间的权重相似性，定义了权重的sigma值。
- **关键数据**：Qwen 3.5 A3B的Base模型sigma值为 **0.01768391**，约为1%上下，表明相似性极高。
- **补充说明**：主流LLM的sigma值普遍较小，具体细节可参考P2论文。

### 行动项
- 进一步研究P2和P3论文中的相关细节。

### 标签
#Qwen3 #weight #LLM #HKU #相似性 #reasoning
- 2026-02-26 17:15:52 UTC | screenshot | ### 核心内容

- **模型信息**  
  - 名称：Qwen3.5-35B-A3B  
  - 参数量：35亿  
  - 每个token活跃参数：30亿  
  - 量化：4-bit  
  - 磁盘占用：19.7GB  

- **运行环境**  
  - 硬件：单张3090显卡  
  - 上下文长度：从4K扩展到262K  
  - 零卸载，所有层运行在GPU上  
  - 性能：4K时112 tok/s，262K时114 tok/s，速度稳定  

- **默认设置问题**  
  - 默认设置在262K上下文时会OOM（内存溢出）  
  - 通过一个标志位解锁，具体解锁命
- 2026-02-26 17:25:47 UTC | screenshot | ### 核心内容

#### 【核心引擎升级】
- **Mamba 前缀缓存**  
  - 使用参数：`--enable-prefix-caching --mamba-cache-mode align`  
  - 直接缓存 Mamba 状态，性能提升约 2 倍。

- **会话式流式输入**  
  - 新增 `StreamingInput API`  
  - 专为 ASR 等交互式场景设计。

- **异步调度 + 流水线并行**  
  - `--async-scheduling` 现已支持 Pipeline Parallelism。

---

#### 【NVIDIA Black
- 2026-02-26 21:42:20 UTC | screenshot | ### 核心内容

1. **性能数据（tok/s）**：
   - **5090**：
     - 166 tok/s (z33b0t)
     - 153 tok/s (EmmanuelMr)
   - **4090**：
     - 122 tok/s (StubbyTech)
   - **3090**：
     - 112 tok/s (sudo)
     - 100 tok/s (Eduardo)
   - **6800XT**：
     - 20-30 tok/s (Dark)

2. **模型信息**：
   - 模型：Qwen3.5-35B-A3B
   - 量化

## Insights
### 今日焦点
用户今天的注意力集中在对大语言模型（LLM）Qwen3.5的性能测试与优化上，尤其是围绕其不同参数规模（35B和27B）的运行表现、硬件适配性以及性能改进方法展开了深入记录。关键词包括“上下文长度扩展”“性能优化”“量化”“并发”“缓存机制”等，表明用户对模型的高效运行和硬件资源利用有强烈兴趣。

### 隐含意图
用户似乎正在评估或优化Qwen3.5模型的性能，可能是为了解决以下问题：
1. **性能瓶颈**：用户关注不同硬件（如4090、3090等）在处理大规模上下文时的性能差异，尤其是上下文长度扩展到200k+后的速度和稳定性。
2. **硬件适配与资源利用**：记录中提到显存占用、OOM（内存溢出）问题以及通过标志位解锁的解决方案，表明用户在探索如何最大化利用现有硬件资源。
3. **优化与扩展**：用户关注如“Mamba前缀缓存”“异步调度+流水线并行”等优化技术，可能是为了提升模型在特定场景（如ASR或交互式任务）中的效率。
4. **模型研究**：用户提到权重相似性（sigma值）和相关论文，可能在为模型的基础研究或进一步改进做准备。

### 未完成信号
1. **性能优化的具体结论未明确**：用户记录了多个硬件和模型配置下的性能数据，但尚未看到明确的对比结论或优化方案的最终选择。
2. **权重相似性研究未深入**：提到需要进一步研究P2和P3论文，但尚未有后续行动。
3. **缓存与并发优化的实际效果未验证**：虽然记录了“Mamba前缀缓存”和“异步调度”的技术细节，但未提及这些优化在实际任务中的具体表现。

### 值得跟进的内容
1. **性能优化的验证与选择**：未来1-3天内，用户可能需要对比不同硬件和优化方案的实际效果，选择最适合的配置。
2. **权重相似性研究**：进一步阅读和分析P2、P3论文，可能为模型改进提供理论支持。
3. **缓存与并发技术的应用场景测试**：需要验证“Mamba前缀缓存”和“StreamingInput API”等技术在实际任务中的表现，尤其是交互式场景。

### 建议行动
1. **整理性能数据并得出结论**：将不同硬件和模型配置下的性能数据进行系统化对比，明确最佳配置方案。
2. **深入研究相关论文**：优先阅读P2和P3论文，提取对权重相似性和模型优化有帮助的理论依据。
3. **测试优化技术的实际效果**：在实际任务中验证“Mamba前缀缓存”“异步调度”等优化技术的性能提升幅度，并记录结果以指导后续决策。
